Segundo Parcial - IA para la EconomÃ­a 2025-2

Universidad de los Andes - Facultad de EconomÃ­a

ğŸ“‹ InformaciÃ³n del Proyecto
Este repositorio contiene el desarrollo del segundo parcial de la materia "IA para la EconomÃ­a", enfocado en la implementaciÃ³n de modelos predictivos (regresiÃ³n logÃ­stica y redes neuronales) utilizando el Adult Dataset de UCI para predecir si una persona gana mÃ¡s de 50k al aÃ±o.

ğŸ¯ Objetivos

Aplicar tÃ©cnicas de preprocesamiento de datos y codificaciÃ³n de variables.

Construir un modelo baseline con regresiÃ³n logÃ­stica.

Implementar y entrenar redes neuronales en PyTorch.

Evaluar y comparar modelos con diferentes configuraciones de hiperparÃ¡metros.

Seleccionar el mejor modelo con un criterio que combine desempeÃ±o en validaciÃ³n y control de sobreajuste.

ğŸ“Š Dataset

Fuente: UCI Adult Dataset

Dimensiones: 48,842 registros Ã— 15 caracterÃ­sticas

Variable objetivo: income (>50k o â‰¤50k)

Variables principales:

DemogrÃ¡ficas: age, race, sex, native_country

Educativas: education, education_num

Laborales: workclass, occupation, hours_per_week, capital_gain, capital_loss

Familiares y sociales: marital_status, relationship

ğŸ›  TecnologÃ­as Utilizadas

Python

LibrerÃ­as principales

pandas, numpy â†’ ManipulaciÃ³n y anÃ¡lisis de datos

scikit-learn â†’ Preprocesamiento, regresiÃ³n logÃ­stica y mÃ©tricas

matplotlib, seaborn â†’ VisualizaciÃ³n de datos y curvas de pÃ©rdida

torch (PyTorch) â†’ ConstrucciÃ³n y entrenamiento de redes neuronales

ğŸ”¬ MetodologÃ­a

ExploraciÃ³n y Preprocesamiento

Carga de datos de train/test desde UCI.

Limpieza de etiquetas en test.

DivisiÃ³n de test en dos subconjuntos (test_1 y test_2).

AnÃ¡lisis de distribuciones de variables categÃ³ricas y objetivo.

CodificaciÃ³n de la variable objetivo con LabelEncoder.

One-hot encoding para variables categÃ³ricas.

EstandarizaciÃ³n de variables numÃ©ricas con StandardScaler.

Modelo Baseline

ImplementaciÃ³n de regresiÃ³n logÃ­stica.

EvaluaciÃ³n en train, test1 y test2 con mÃ©tricas: accuracy, precisiÃ³n, recall, F1-score, AUC.

Redes Neuronales (sin regularizaciÃ³n)

ConstrucciÃ³n de un MLP con PyTorch.

Pruebas con diferentes nÃºmeros de capas ocultas, neuronas y learning rates.

Curvas de pÃ©rdida para analizar comportamiento.

Redes Neuronales (con Dropout y Early Stopping)

Arquitectura extendida con Dropout.

Estrategia de Early Stopping para detener entrenamiento cuando la validaciÃ³n deja de mejorar.

Cinco experimentos con diferentes configuraciones de hiperparÃ¡metros (capas, neuronas, dropout, lr, weight decay).

EvaluaciÃ³n en train, validaciÃ³n y test.

SelecciÃ³n del Mejor Modelo

DefiniciÃ³n de un composite score:

score
=
AUC
ğ‘£
ğ‘
ğ‘™
âˆ’
ğ›¼
â‹…
gapÂ (train-val)
âˆ’
ğ›½
â‹…
val_loss
score=AUC
val
	â€‹

âˆ’Î±â‹…gapÂ (train-val)âˆ’Î²â‹…val_loss

Criterio balanceado que prioriza buen desempeÃ±o en validaciÃ³n y bajo sobreajuste.
